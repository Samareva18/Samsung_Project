{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "QMWMFuzKuXO2"
      },
      "outputs": [],
      "source": [
        "    import torch\n",
        "    import torchvision\n",
        "    import sys\n",
        "    import torch\n",
        "    import numpy as np\n",
        "    import cv2\n",
        "    import matplotlib.pyplot as plt\n",
        "    import warnings\n",
        "    import zipfile\n",
        "    import io\n",
        "    import glob\n",
        "    import os\n",
        "    !{sys.executable} -m pip install opencv-python matplotlib onnx onnxruntime\n",
        "    !{sys.executable} -m pip install 'git+https://github.com/facebookresearch/segment-anything.git'\n",
        "    !mkdir images\n",
        "    !wget https://dl.fbaipublicfiles.com/segment_anything/sam_vit_h_4b8939.pth\n",
        "    from segment_anything import sam_model_registry, SamPredictor\n",
        "    from segment_anything.utils.onnx import SamOnnxModel\n",
        "    import onnxruntime\n",
        "    from onnxruntime.quantization import QuantType\n",
        "    from onnxruntime.quantization.quantize import quantize_dynamic"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "njCWztgVcM0O",
        "collapsed": true
      },
      "outputs": [],
      "source": [
        "from google.colab import files\n",
        "uploaded = files.upload()\n",
        "image1_path = list(uploaded.keys())[0]\n",
        "image1 = cv2.imread(image1_path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TSs04CTFcOR7",
        "collapsed": true
      },
      "outputs": [],
      "source": [
        "from google.colab import files\n",
        "uploaded = files.upload()\n",
        "lvda_mask_path = list(uploaded.keys())[0]\n",
        "lvda_mask_image = cv2.imread(lvda_mask_path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OZN7FeKSzfHw"
      },
      "outputs": [],
      "source": [
        "checkpoint = \"sam_vit_h_4b8939.pth\"\n",
        "model_type = \"vit_h\"\n",
        "sam = sam_model_registry[model_type](checkpoint=checkpoint)\n",
        "onnx_model_path = \"sam_onnx_example.onnx\"\n",
        "onnx_model = SamOnnxModel(sam, return_single_mask=True)\n",
        "dynamic_axes = {\n",
        "    \"point_coords\": {1: \"num_points\"},\n",
        "    \"point_labels\": {1: \"num_points\"},\n",
        "}\n",
        "embed_dim = sam.prompt_encoder.embed_dim\n",
        "embed_size = sam.prompt_encoder.image_embedding_size\n",
        "mask_input_size = [4 * x for x in embed_size]\n",
        "dummy_inputs = {\n",
        "    \"image_embeddings\": torch.randn(1, embed_dim, *embed_size, dtype=torch.float),\n",
        "    \"point_coords\": torch.randint(low=0, high=1024, size=(1, 5, 2), dtype=torch.float),\n",
        "    \"point_labels\": torch.randint(low=0, high=4, size=(1, 5), dtype=torch.float),\n",
        "    \"mask_input\": torch.randn(1, 1, *mask_input_size, dtype=torch.float),\n",
        "    \"has_mask_input\": torch.tensor([1], dtype=torch.float),\n",
        "    \"orig_im_size\": torch.tensor([1500, 2250], dtype=torch.float),\n",
        "}\n",
        "output_names = [\"masks\", \"iou_predictions\", \"low_res_masks\"]\n",
        "with warnings.catch_warnings():\n",
        "    warnings.filterwarnings(\"ignore\", category=torch.jit.TracerWarning)\n",
        "    warnings.filterwarnings(\"ignore\", category=UserWarning)\n",
        "    with open(onnx_model_path, \"wb\") as f:\n",
        "        torch.onnx.export(\n",
        "            onnx_model,\n",
        "            tuple(dummy_inputs.values()),\n",
        "            f,\n",
        "            export_params=True,\n",
        "            verbose=False,\n",
        "            opset_version=17,\n",
        "            do_constant_folding=True,\n",
        "            input_names=list(dummy_inputs.keys()),\n",
        "            output_names=output_names,\n",
        "            dynamic_axes=dynamic_axes,\n",
        "        )\n",
        "\n",
        "ort_session = onnxruntime.InferenceSession(onnx_model_path)\n",
        "\n",
        "sam.to(device='cpu')\n",
        "predictor = SamPredictor(sam)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "AJpyhtpUzwi0"
      },
      "outputs": [],
      "source": [
        "#создает синий контур у маски из loveDA\n",
        "def get_contour_loveda_mask(path):\n",
        "    loveda_mask = cv2.imread(path, cv2.IMREAD_GRAYSCALE)\n",
        "    loveda_mask = np.where(loveda_mask == 64, 1, 0)\n",
        "    loveda_mask = loveda_mask.astype(np.uint8)\n",
        "    loveda_mask = loveda_mask * 255\n",
        "    contours, hierarchy = cv2.findContours(loveda_mask, cv2.RETR_CCOMP, cv2.CHAIN_APPROX_SIMPLE)\n",
        "\n",
        "    mask_with_fill_contours = cv2.cvtColor(loveda_mask, cv2.COLOR_GRAY2BGR)\n",
        "    cv2.drawContours(mask_with_fill_contours, contours, -1, (255, 0, 0), thickness=2)\n",
        "\n",
        "    return mask_with_fill_contours\n",
        "\n",
        "\n",
        "#накладывает синий контур маски из набора на изображение\n",
        "def overlay_lvda_contour(origin_img, mask):\n",
        "    height, width, channels = origin_img.shape\n",
        "    for y in range(height):\n",
        "        for x in range(width):\n",
        "            if (mask[y, x][0] > 200 and mask[y, x][1] < 10 and mask[y, x][2] < 10):\n",
        "                origin_img[y, x] = np.array([0, 0, 255])\n",
        "\n",
        "    return origin_img\n",
        "\n",
        "def get_image4(image_path, mask_path):\n",
        "    image = cv2.imread(image_path)\n",
        "    image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
        "    image4 = overlay_lvda_contour(image, get_contour_loveda_mask(mask_path))\n",
        "    return image4\n",
        "\n",
        "def show_img(img):\n",
        "    plt.axis('off')\n",
        "    plt.imshow(img)\n",
        "    plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#IOU\n",
        "\n",
        "def get_binary_lvda_mask(mask_path):\n",
        "    mask = cv2.imread(mask_path, cv2.IMREAD_GRAYSCALE)\n",
        "    mask = np.where(mask == 64, 1, 0)\n",
        "    mask = mask.astype(np.uint8)\n",
        "    mask = mask * 255\n",
        "    return mask\n",
        "\n",
        "def get_binary_sam_mask(sam_mask):\n",
        "    mask = cv2.cvtColor(sam_mask, cv2.COLOR_BGR2GRAY)\n",
        "    _, bin_sam = cv2.threshold(mask, 50, 255, cv2.THRESH_BINARY)\n",
        "    return bin_sam\n",
        "\n",
        "\n",
        "def calculate_iou(mask_path, sam_mask):\n",
        "    gt_mask = get_binary_lvda_mask(mask_path)\n",
        "    pred_mask = get_binary_sam_mask(sam_mask)\n",
        "    intersection = np.logical_and(gt_mask, pred_mask)\n",
        "    eps = 1e-7\n",
        "    union = np.logical_or(gt_mask, pred_mask) + eps\n",
        "    iou_score = (np.sum(intersection) + eps) / np.sum(union)\n",
        "    return round(iou_score, 2)"
      ],
      "metadata": {
        "id": "vwujF481SDQC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "1ZemPSWi4xC8"
      },
      "outputs": [],
      "source": [
        "# функция для нахождения точек принадлежащих объектам воды\n",
        "def get_points_of_object(mask_path):\n",
        "    points = []\n",
        "    mask = cv2.imread(mask_path, cv2.IMREAD_GRAYSCALE)\n",
        "    mask = np.where(mask == 64, 1, 0)\n",
        "    mask = mask.astype(np.uint8)\n",
        "    mask = mask * 255\n",
        "\n",
        "    ret, binary_mask = cv2.threshold(mask, 30, 255, cv2.THRESH_BINARY)\n",
        "    contours, hierarchy = cv2.findContours(binary_mask, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
        "\n",
        "    for contour in contours:\n",
        "        try:\n",
        "            black_image = np.zeros_like(mask)\n",
        "            cv2.drawContours(black_image, [contour], -1, (255, 0, 0), thickness=cv2.FILLED)\n",
        "\n",
        "            x, y, dx, dy = cv2.boundingRect(contour)\n",
        "            midY = int(dy / 2 + y)\n",
        "            x_values = []\n",
        "\n",
        "            startX = x\n",
        "            endX = x + dx\n",
        "\n",
        "            for x in range(startX, endX):\n",
        "                if black_image[midY, x] == 255:\n",
        "                    x_values.append(x)\n",
        "            sorted_x_val = sorted(x_values)\n",
        "            x_arr = []\n",
        "            for i in range(2, len(sorted_x_val)):\n",
        "                if (sorted_x_val[i] - sorted_x_val[i - 1]) < 3:\n",
        "                    x_arr.append(sorted_x_val[i])\n",
        "                else:\n",
        "                    break\n",
        "\n",
        "            midX = int((x_arr[0] + x_arr[-1]) / 2)\n",
        "\n",
        "            point = [midX, midY]\n",
        "            points.append(point)\n",
        "\n",
        "        except Exception:\n",
        "            continue\n",
        "\n",
        "    return points"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def check_iou_sam_contour(mask_path, point, sam_contour_mask):\n",
        "    mask = cv2.imread(mask_path, cv2.IMREAD_GRAYSCALE)\n",
        "    mask = np.where(mask == 64, 1, 0)\n",
        "    mask = mask.astype(np.uint8)\n",
        "    mask = mask * 255\n",
        "\n",
        "    ret, binary_mask = cv2.threshold(mask, 30, 255, cv2.THRESH_BINARY)\n",
        "    contours, hierarchy = cv2.findContours(binary_mask, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
        "\n",
        "    for contour in contours:\n",
        "        distance = cv2.pointPolygonTest(contour, point, True)\n",
        "        if distance > 0:\n",
        "            gt_mask = np.zeros((1024, 1024), dtype=np.uint8)\n",
        "            cv2.drawContours(gt_mask, [contour], contourIdx=-1, color=255, thickness=cv2.FILLED)\n",
        "\n",
        "            gt_mask = gt_mask.astype(np.uint8)\n",
        "            gt_mask = gt_mask * 255\n",
        "\n",
        "            pred_mask = sam_contour_mask\n",
        "\n",
        "            intersection = np.logical_and(gt_mask, pred_mask)\n",
        "            eps = 1e-7\n",
        "            union = np.logical_or(gt_mask, pred_mask) + eps\n",
        "            iou_score = (np.sum(intersection) + eps) / np.sum(union)\n",
        "            idx_iou = round(iou_score, 2)\n",
        "\n",
        "            if idx_iou < 0.4:\n",
        "                return gt_mask\n",
        "\n",
        "            break\n",
        "\n",
        "    return pred_mask"
      ],
      "metadata": {
        "id": "rhg-DWqETUM-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_sam_mask(image, mask_path):\n",
        "    predictor.set_image(image)\n",
        "    image_embedding = predictor.get_image_embedding().cpu().numpy()\n",
        "    image_embedding.shape\n",
        "    masks_arr = []\n",
        "    points = get_points_of_object(mask_path)\n",
        "\n",
        "\n",
        "    for point in points:\n",
        "        input_point = np.array([point])\n",
        "        input_label = np.array([1])\n",
        "\n",
        "        onnx_coord = np.concatenate([input_point, np.array([[0.0, 0.0]])], axis=0)[None, :, :]\n",
        "        onnx_label = np.concatenate([input_label, np.array([-1])], axis=0)[None, :].astype(np.float32)\n",
        "        onnx_coord = predictor.transform.apply_coords(onnx_coord, image.shape[:2]).astype(np.float32)\n",
        "\n",
        "        onnx_mask_input = np.zeros((1, 1, 256, 256), dtype=np.float32)\n",
        "        onnx_has_mask_input = np.zeros(1, dtype=np.float32)\n",
        "\n",
        "        ort_inputs = {\n",
        "            \"image_embeddings\": image_embedding,\n",
        "            \"point_coords\": onnx_coord,\n",
        "            \"point_labels\": onnx_label,\n",
        "            \"mask_input\": onnx_mask_input,\n",
        "            \"has_mask_input\": onnx_has_mask_input,\n",
        "            \"orig_im_size\": np.array(image.shape[:2], dtype=np.float32)\n",
        "        }\n",
        "\n",
        "        masks, _, low_res_logits = ort_session.run(None, ort_inputs)\n",
        "        masks = masks > predictor.model.mask_threshold\n",
        "\n",
        "        masks.shape\n",
        "        mask = np.squeeze(masks)\n",
        "        check_mask = check_iou_sam_contour(mask_path, point, mask)# здесь сделать проверку iou\n",
        "        masks_arr.append(check_mask)\n",
        "\n",
        "    color = np.array([30, 144, 255], dtype=np.float32)\n",
        "    sam_mask = np.zeros_like(image, dtype=np.float32)\n",
        "\n",
        "  # здесь все маски накладываются\n",
        "    for mask in masks_arr:\n",
        "        show_img(mask)\n",
        "        sam_mask[mask == 1] = color\n",
        "\n",
        "    sam_mask = sam_mask.astype('uint8')\n",
        "\n",
        "    return sam_mask\n"
      ],
      "metadata": {
        "id": "2ZGkeDsySfqw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "AGXieCY298aQ"
      },
      "outputs": [],
      "source": [
        "#создает красный контур у маски sam\n",
        "def get_contour_sam_mask(mask_image):\n",
        "    gray = cv2.cvtColor(mask_image, cv2.COLOR_BGR2GRAY)\n",
        "    ret, thresh = cv2.threshold(gray, 100, 255, cv2.THRESH_BINARY)\n",
        "    contours, hierarchy = cv2.findContours(thresh, cv2.RETR_CCOMP, cv2.CHAIN_APPROX_SIMPLE)\n",
        "    cv2.drawContours(mask_image, contours, -1, (255, 0, 0), 2)\n",
        "    return mask_image\n",
        "\n",
        "#накладывает красный контур маски sam на изображение\n",
        "def overlay_mask_contour(origin_img, mask):\n",
        "    height, width, channels = origin_img.shape\n",
        "    for y in range(height):\n",
        "        for x in range(width):\n",
        "            if mask[y, x][0] >= 200 and mask[y, x][1] <= 50 and mask[y, x][2] <= 50:\n",
        "                origin_img[y, x] = np.array([255, 0, 0])\n",
        "\n",
        "    return origin_img\n",
        "\n",
        "def get_image3(image_path, mask_path, sam_mask):\n",
        "    image = cv2.imread(image_path)\n",
        "    image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
        "    image3 = overlay_mask_contour(image, get_contour_sam_mask(sam_mask))\n",
        "    return image3"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "d5YVEfMtFiVd"
      },
      "outputs": [],
      "source": [
        "#создает красную заполненную маску из набора\n",
        "def get_contour_mask(mask_path):\n",
        "    image = cv2.imread(mask_path, cv2.IMREAD_GRAYSCALE)\n",
        "    image = np.where(image == 64, 1, 0)\n",
        "    image = image.astype(np.uint8)\n",
        "    image = image * 255\n",
        "\n",
        "    ret, binary_mask = cv2.threshold(image, 40, 100, cv2.THRESH_BINARY)\n",
        "    contours, hierarchy = cv2.findContours(binary_mask, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
        "\n",
        "    mask_with_fill_contours = cv2.cvtColor(image, cv2.COLOR_GRAY2BGR)\n",
        "    cv2.drawContours(mask_with_fill_contours, contours, -1, (0, 0, 255), thickness=cv2.FILLED)\n",
        "\n",
        "    return mask_with_fill_contours\n",
        "\n",
        "#накладывает прозрачную белую маску из набора\n",
        "def overlay_transparent_loveda_mask(image_path, mask_path):\n",
        "    original_image = cv2.imread(image_path)\n",
        "    original_image = cv2.cvtColor(original_image, cv2.COLOR_BGR2RGB)\n",
        "    mask = get_contour_mask(mask_path)\n",
        "\n",
        "    red_mask = cv2.inRange(mask, (0, 0, 200), (100, 100, 255))\n",
        "    red_mask = cv2.cvtColor(red_mask, cv2.COLOR_GRAY2BGR)\n",
        "\n",
        "    result = cv2.addWeighted(original_image, 1, red_mask, 0.4, 0)\n",
        "\n",
        "    return result\n",
        "\n",
        "#накладывает красный контур sam\n",
        "def overlay_sam_contour(origin_img, mask):\n",
        "    height, width, channels = origin_img.shape\n",
        "    for y in range(height):\n",
        "        for x in range(width):\n",
        "            if (mask[y, x][0] > 200 and mask[y, x][1] < 10 and mask[y, x][2] < 10):\n",
        "                origin_img[y, x] = np.array([255, 0, 0])\n",
        "\n",
        "    return origin_img\n",
        "\n",
        "\n",
        "def get_image2(image_path, mask_path, img3):\n",
        "    img2 = overlay_transparent_loveda_mask(image_path, mask_path)\n",
        "    image2 = overlay_sam_contour(img2, img3)\n",
        "    return image2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gpTH81_0c_mT"
      },
      "outputs": [],
      "source": [
        "def get_sam_mask_for_folder(sam_mask):\n",
        "    mask = get_binary_sam_mask(sam_mask)\n",
        "    mask[mask == 255] = 64\n",
        "    mask = cv2.cvtColor(mask, cv2.COLOR_GRAY2BGR)\n",
        "    return mask"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hySBeQbpnv-I",
        "collapsed": true
      },
      "outputs": [],
      "source": [
        "from google.colab import files\n",
        "uploaded = files.upload()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3GrG_DNntBBA",
        "collapsed": true
      },
      "outputs": [],
      "source": [
        "uploaded1 = files.upload()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GrhGgMQgtHd5"
      },
      "outputs": [],
      "source": [
        "zip_file = zipfile.ZipFile(io.BytesIO(uploaded['images.zip']), 'r')\n",
        "zip_file.extractall('images_folder')\n",
        "\n",
        "zip_file1 = zipfile.ZipFile(io.BytesIO(uploaded1['masks.zip']), 'r')\n",
        "zip_file1.extractall('masks_folder')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RxQoC0Zw_sAw"
      },
      "outputs": [],
      "source": [
        "res_fold = 'images'\n",
        "os.makedirs(res_fold, exist_ok=True)\n",
        "\n",
        "masks_folder = 'gt2'\n",
        "os.makedirs(masks_folder, exist_ok=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Dyyenm31t9tf",
        "collapsed": true
      },
      "outputs": [],
      "source": [
        "images = glob.glob('images_folder/images/*.tif')\n",
        "masks = glob.glob('masks_folder/masks/*.tif')\n",
        "\n",
        "i = 0\n",
        "for image in images:\n",
        "    img_name = image.split('/')[-1]\n",
        "    for mask in masks:\n",
        "        msk_name = mask.split('/')[-1]\n",
        "        if img_name == msk_name:\n",
        "            i+=1\n",
        "            print(i)\n",
        "            img1 = cv2.imread(image)\n",
        "            points = get_points_of_object(mask)\n",
        "\n",
        "            #если есть объекты воды, то обрабатываем картинки и сохраняем\n",
        "            if points:\n",
        "                sam_mask = get_sam_mask(img1, mask)\n",
        "\n",
        "                img4 = get_image4(image, mask)\n",
        "                img3 = get_image3(image, mask, sam_mask)\n",
        "                img2 = get_image2(image, mask, img3)\n",
        "\n",
        "                img2 = cv2.cvtColor(img2, cv2.COLOR_BGR2RGB)\n",
        "                img3 = cv2.cvtColor(img3, cv2.COLOR_BGR2RGB)\n",
        "                img4 = cv2.cvtColor(img4, cv2.COLOR_BGR2RGB)\n",
        "\n",
        "                iou = calculate_iou(mask, sam_mask)\n",
        "\n",
        "                #сохранение обработанных картинок в папку\n",
        "                img1_path = os.path.join(res_fold, img_name.split('.')[0]+'_1_iou_' + str(iou) + '.tif')\n",
        "                cv2.imwrite(img1_path, img1)\n",
        "\n",
        "                img2_path = os.path.join(res_fold, img_name.split('.')[0]+'_2_iou_' + str(iou) + '.tif')\n",
        "                cv2.imwrite(img2_path, img2)\n",
        "\n",
        "                img3_path = os.path.join(res_fold, img_name.split('.')[0]+'_3_iou_' + str(iou) + '.tif')\n",
        "                cv2.imwrite(img3_path, img3)\n",
        "\n",
        "                img4_path = os.path.join(res_fold, img_name.split('.')[0]+'_4_iou_' + str(iou) + '.tif')\n",
        "                cv2.imwrite(img4_path, img4)\n",
        "\n",
        "                #сохранение маски сэм в папку\n",
        "                mask = get_sam_mask_for_folder(sam_mask)\n",
        "                mask_path = os.path.join(masks_folder, img_name)\n",
        "                cv2.imwrite(mask_path, mask)\n",
        "            else:\n",
        "                img1_path = os.path.join(res_fold, img_name.split('.')[0] + '.tif')\n",
        "                cv2.imwrite(img1_path, img1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xCno6sfuSd0w"
      },
      "outputs": [],
      "source": [
        "zipf = zipfile.ZipFile(res_fold + '.zip', 'w', zipfile.ZIP_DEFLATED)\n",
        "for root, dirs, files in os.walk(res_fold):\n",
        "    for file in files:\n",
        "        zipf.write(os.path.join(root, file))\n",
        "zipf.close()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hC2kRT07StDa",
        "collapsed": true
      },
      "outputs": [],
      "source": [
        "from google.colab import files\n",
        "\n",
        "files.download(res_fold + '.zip')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qRpCjT2cSzNQ"
      },
      "outputs": [],
      "source": [
        "zipf_m = zipfile.ZipFile(masks_folder + '.zip', 'w', zipfile.ZIP_DEFLATED)\n",
        "for root, dirs, files in os.walk(masks_folder):\n",
        "    for file in files:\n",
        "        zipf_m.write(os.path.join(root, file))\n",
        "zipf_m.close()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9_VeY_okpDRi",
        "collapsed": true
      },
      "outputs": [],
      "source": [
        "from google.colab import files\n",
        "\n",
        "files.download(masks_folder + '.zip')"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}